{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_VISSL_Tutorial_With_ZTF_Images.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKU-PjSp7_fs"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\n",
        "# edited by Richard Terrile to facilitate use with ZTF image data."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Understanding VISSL Training and YAML Config and Using ZTF Image Data\n",
        "\n",
        "This tutorial will guide you through using a Supervised ResNet-50 model on custom data from the Zwicky Transient Facility, and understanding various parts of the model training configuration.\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. DO NOT request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has a GPU available. To ensure/select this, simply follow: `Edit -> Notebook Settings -> select GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcE1zeDElnvK"
      },
      "source": [
        "##Introduction and Outline\n",
        "This tutorial will walk through the following steps:\n",
        "- Introduction to VISSL\n",
        "- Installing VISSL\n",
        "- Downloading YAML file for Supervised Training using resnet-50 model\n",
        "- Download VISSL Training tool\n",
        "- Creating a Custom Dataset\n",
        "- Downloading ZTF Image Data\n",
        "- Registering the Custom Data with VISSL\n",
        "- Training the Model\n",
        "- Training Logs and Checkpoints\n",
        "- Understanding the Training Command\n",
        "- Understanding the Training stdout\n",
        "- Understanding the YAML Configuration File\n",
        "- Visualization using Tensorboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "# Install VISSL\n",
        "\n",
        "Installing VISSL is pretty straightfoward. Use pip binaries of VISSL and follow instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ISg59KTOqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433906b3-9fab-4208-e2c0-e715537e33c2"
      },
      "source": [
        "# installing pytorch and torchvision\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# installing apex\n",
        "!pip install -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py37_cu101_pyt171/download.html apex\n",
        "# clone vissl repository\n",
        "!git clone --recursive https://github.com/facebookresearch/vissl.git \n",
        "# install vissl dependencies\n",
        "!pip install --progress-bar off -r requirements.txt\n",
        "!pip install opencv-python\n",
        "# update classy vision install to current master\n",
        "!pip uninstall -y classy_vision\n",
        "!pip install classy-vision@https://github.com/facebookresearch/ClassyVision/tarball/master"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu101 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.8.2+cu101 in /usr/local/lib/python3.7/dist-packages (0.8.2+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu101) (7.1.2)\n",
            "Looking in links: https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py37_cu101_pyt171/download.html\n",
            "Requirement already satisfied: apex in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "fatal: destination path 'vissl' already exists and is not an empty directory.\n",
            "Collecting fairscale@ https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6\n",
            "  Using cached https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython==0.29.22 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.29.22)\n",
            "Requirement already satisfied: fvcore==0.1.3.post20210317 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.1.3.post20210317)\n",
            "Requirement already satisfied: hydra-core==1.0.6 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.0.6)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: parameterized==0.7.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.7.4)\n",
            "Requirement already satisfied: scikit-learn==0.24.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.24.1)\n",
            "Requirement already satisfied: submitit==1.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: tabulate==0.8.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.8.9)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fairscale@ https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6->-r requirements.txt (line 4)) (1.7.1+cu101)\n",
            "Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->-r requirements.txt (line 5)) (0.1.9)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->-r requirements.txt (line 5)) (5.4.1)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->-r requirements.txt (line 5)) (0.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->-r requirements.txt (line 5)) (4.62.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.0.6->-r requirements.txt (line 6)) (4.8)\n",
            "Requirement already satisfied: omegaconf<2.1,>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.0.6->-r requirements.txt (line 6)) (2.0.6)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.0.6->-r requirements.txt (line 6)) (5.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 9)) (2.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from submitit==1.3.3->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from submitit==1.3.3->-r requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->fvcore==0.1.3.post20210317->-r requirements.txt (line 5)) (2.3.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core==1.0.6->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Found existing installation: classy-vision 0.7.0.dev0\n",
            "Uninstalling classy-vision-0.7.0.dev0:\n",
            "  Successfully uninstalled classy-vision-0.7.0.dev0\n",
            "Collecting classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master\n",
            "  Using cached https://github.com/facebookresearch/ClassyVision/tarball/master\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (0.8.2+cu101)\n",
            "Requirement already satisfied: fvcore>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (0.1.3.post20210317)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (7.1.2)\n",
            "Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (0.1.9)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (0.8.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (5.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (4.62.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (1.1.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->fvcore>=0.1.3->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (2.3.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->classy-vision@ https://github.com/facebookresearch/ClassyVision/tarball/master) (3.7.4.3)\n",
            "Building wheels for collected packages: classy-vision\n",
            "  Building wheel for classy-vision (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for classy-vision: filename=classy_vision-0.7.0.dev0-py3-none-any.whl size=356934 sha256=93e3ed0a8b3d0fd8ba663c20df5b74249d2c1164af742b74594416456f383c2e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b1b8120t/wheels/fb/21/0e/6746f581528e4b1c0e1672f51e09bfd607e3246ad038888df9\n",
            "Successfully built classy-vision\n",
            "Installing collected packages: classy-vision\n",
            "Successfully installed classy-vision-0.7.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7j1S0ZDcrAc"
      },
      "source": [
        "Now you will install .[dev] inside the /vissl folder manually. Navigate to the folder and run the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh87uRvpQIDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8635c703-2983-4512-e41d-9429c75e2f5e"
      },
      "source": [
        "cd /content/vissl"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vissl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLaeQWZOprEJ"
      },
      "source": [
        "The following command will install .[dev]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoZoXK_vQJUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4879870-1f4b-4779-b9c2-08588dbf8d46"
      },
      "source": [
        "!pip install \".[dev]\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/vissl\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting fairscale@ https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6\n",
            "  Using cached https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython==0.29.22 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (0.29.22)\n",
            "Requirement already satisfied: fvcore==0.1.3.post20210317 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (0.1.3.post20210317)\n",
            "Requirement already satisfied: hydra-core==1.0.6 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (1.0.6)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (1.19.5)\n",
            "Requirement already satisfied: parameterized==0.7.4 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (0.7.4)\n",
            "Requirement already satisfied: scikit-learn==0.24.1 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (0.24.1)\n",
            "Requirement already satisfied: submitit==1.3.3 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (1.3.3)\n",
            "Requirement already satisfied: tabulate==0.8.9 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (0.8.9)\n",
            "Requirement already satisfied: black==19.3b0 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (19.3b0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (1.8.5)\n",
            "Requirement already satisfied: isort==5.7.0 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (5.7.0)\n",
            "Requirement already satisfied: flake8==3.8.1 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (3.8.1)\n",
            "Requirement already satisfied: flake8-bugbear in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (21.4.3)\n",
            "Requirement already satisfied: flake8-comprehensions in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (3.6.1)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (2.14.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (5.6.1)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (0.0.1)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (1.7.1.post2)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (2.0.2)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.7/dist-packages (from vissl==0.1.5) (2.6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fairscale@ https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6->vissl==0.1.5) (1.7.1+cu101)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==19.3b0->vissl==0.1.5) (1.4.4)\n",
            "Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from black==19.3b0->vissl==0.1.5) (0.10.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from black==19.3b0->vissl==0.1.5) (21.2.0)\n",
            "Requirement already satisfied: click>=6.5 in /usr/local/lib/python3.7/dist-packages (from black==19.3b0->vissl==0.1.5) (7.1.2)\n",
            "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from flake8==3.8.1->vissl==0.1.5) (2.2.0)\n",
            "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /usr/local/lib/python3.7/dist-packages (from flake8==3.8.1->vissl==0.1.5) (2.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from flake8==3.8.1->vissl==0.1.5) (4.6.4)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8==3.8.1->vissl==0.1.5) (0.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->vissl==0.1.5) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->vissl==0.1.5) (4.62.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->vissl==0.1.5) (5.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->vissl==0.1.5) (7.1.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->vissl==0.1.5) (0.1.8)\n",
            "Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.3.post20210317->vissl==0.1.5) (0.1.9)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.0.6->vissl==0.1.5) (4.8)\n",
            "Requirement already satisfied: omegaconf<2.1,>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.0.6->vissl==0.1.5) (2.0.6)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.0.6->vissl==0.1.5) (5.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->vissl==0.1.5) (2.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->vissl==0.1.5) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->vissl==0.1.5) (1.0.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from submitit==1.3.3->vissl==0.1.5) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from submitit==1.3.3->vissl==0.1.5) (3.7.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->fvcore==0.1.3.post20210317->vissl==0.1.5) (2.3.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->vissl==0.1.5) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->vissl==0.1.5) (57.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl==0.1.5) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl==0.1.5) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl==0.1.5) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl==0.1.5) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools>=2.0.1->vissl==0.1.5) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (1.39.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (0.4.5)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (1.34.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->vissl==0.1.5) (0.37.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->vissl==0.1.5) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->vissl==0.1.5) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->vissl==0.1.5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->vissl==0.1.5) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.15->vissl==0.1.5) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->vissl==0.1.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->vissl==0.1.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->vissl==0.1.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->vissl==0.1.5) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->vissl==0.1.5) (3.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->vissl==0.1.5) (4.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->flake8==3.8.1->vissl==0.1.5) (3.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (0.3)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (5.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (0.8.4)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (5.0.5)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (0.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (2.6.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (4.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (4.7.1)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->vissl==0.1.5) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert->vissl==0.1.5) (2.0.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert->vissl==0.1.5) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert->vissl==0.1.5) (0.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->vissl==0.1.5) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->vissl==0.1.5) (21.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->vissl==0.1.5) (2.2.13)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pre-commit->vissl==0.1.5) (1.6.0)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->vissl==0.1.5) (3.3.1)\n",
            "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.7/dist-packages (from pre-commit->vissl==0.1.5) (20.7.2)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->vissl==0.1.5) (2.3.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->vissl==0.1.5) (0.3.2)\n",
            "Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->vissl==0.1.5) (3.0.12)\n",
            "Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->vissl==0.1.5) (1.1.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->vissl==0.1.5) (2.1.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->vissl==0.1.5) (0.17.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->vissl==0.1.5) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->vissl==0.1.5) (1.2.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->vissl==0.1.5) (1.2.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->vissl==0.1.5) (2.9.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx->vissl==0.1.5) (2018.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->vissl==0.1.5) (1.1.5)\n",
            "Building wheels for collected packages: vissl\n",
            "  Building wheel for vissl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vissl: filename=vissl-0.1.5-py3-none-any.whl size=991580 sha256=eccc019c30e31d6113764ed897645e2b3e35715b3a5e0f92318b156145a4ae4c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vh4yz84b/wheels/71/e3/c1/b6ac19eac61de8dd67b0ba8f36a9771b981f5e579e91dd3aaf\n",
            "Successfully built vissl\n",
            "Installing collected packages: vissl\n",
            "  Attempting uninstall: vissl\n",
            "    Found existing installation: vissl 0.1.5\n",
            "    Uninstalling vissl-0.1.5:\n",
            "      Successfully uninstalled vissl-0.1.5\n",
            "Successfully installed vissl-0.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "vissl"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BisUOhfp01V"
      },
      "source": [
        "Finally run this line to finish installing VISSL and apex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmcKK0NMQKki"
      },
      "source": [
        "!python -c 'import vissl, apex'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available.  Run the following code cell to make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEHZ4KdxzWq"
      },
      "source": [
        "# YAML config file for Supervised Training\n",
        "\n",
        "Definition of YAML via https://blog.stackpath.com/yaml/:\n",
        "- YAML is a human-readable data serialization standard that can be used in conjunction with all programming languages and is often used to write configuration files.\n",
        "\n",
        "VISSL provides YAML configuration files that reproduce training of all self-supervised approaches [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/pretrain/supervised). \n",
        "\n",
        "For the purpose of this tutorial, we will use the config file for training ResNet-50 supervised model on 1-gpu. Let's go ahead and download the [example config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/pretrain/supervised/supervised_1gpu_resnet_example.yaml).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufyNAeUaDSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9c0bb4-d834-4bed-bd84-6db9b113a9f8"
      },
      "source": [
        "!mkdir -p configs/config/\n",
        "!wget -O configs/__init__.py https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py \n",
        "!wget -O configs/config/supervised_1gpu_resnet_example.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/supervised_1gpu_resnet_example.yaml"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-01 00:25:30--  https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71 [text/plain]\n",
            "Saving to: ‘configs/__init__.py’\n",
            "\n",
            "configs/__init__.py 100%[===================>]      71  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-01 00:25:31 (11.5 MB/s) - ‘configs/__init__.py’ saved [71/71]\n",
            "\n",
            "--2021-09-01 00:25:31--  https://dl.fbaipublicfiles.com/vissl/tutorials/configs/supervised_1gpu_resnet_example.yaml\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2673 (2.6K) [text/plain]\n",
            "Saving to: ‘configs/config/supervised_1gpu_resnet_example.yaml’\n",
            "\n",
            "configs/config/supe 100%[===================>]   2.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-01 00:25:32 (33.2 MB/s) - ‘configs/config/supervised_1gpu_resnet_example.yaml’ saved [2673/2673]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNMJGSRyffl"
      },
      "source": [
        "## Built-in training tool in VISSL\n",
        "\n",
        "VISSL also provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/master/tools/run_distributed_engines.py) that allows to use VISSL for training purposes. This tool offers:\n",
        "- allows training and feature extraction both using VISSL. \n",
        "- also allows training on 1-gpu or multi-gpu. \n",
        "- can be used to launch multi-machine distributed training.\n",
        "\n",
        "This tool is how you will be training your model.\n",
        "\n",
        "Let's go ahead and download this tool directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6io7qQWzCbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6157de8-f199-4b97-f65b-75296b216c1f"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-01 00:25:32--  https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6568 (6.4K) [text/x-python]\n",
            "Saving to: ‘run_distributed_engines.py.2’\n",
            "\n",
            "run_distributed_eng 100%[===================>]   6.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-01 00:25:33 (57.5 MB/s) - ‘run_distributed_engines.py.2’ saved [6568/6568]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a custom dataset\n",
        "\n",
        "The dataset uses the folder style below.  Run the code below to create the directories and then we will download the image data.  Differently labelled data will be stored in different label folders (ie. label1, label2, etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "source": [
        "!mkdir -p custom_data/train/label1\n",
        "!mkdir -p custom_data/train/label2\n",
        "!mkdir -p custom_data/val/label1\n",
        "!mkdir -p custom_data/val/label2"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwxKbo6sQgEn"
      },
      "source": [
        "## Downloading ZTF Image Data\n",
        "\n",
        "After creating the custom data folders, find the image data you desire and download it into the appropriate image label folders.  First download ztfquery."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYGAx1nne_Z7",
        "outputId": "49f841d3-7a02-4e4f-cb98-6b9e86883f26"
      },
      "source": [
        "pip install ztfquery"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ztfquery in /usr/local/lib/python3.7/dist-packages (1.15.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XkkMgJJRP0e"
      },
      "source": [
        "Using the following code, print out wget commands to retrieve all the desired image data and save it to the appropriate image label folder.  \n",
        "\n",
        "Change 'ra' and 'dec' variables to the desired position on the sky.  You must also change the username and password in the wget commands.  And remember to change the save directory at the end of the commands.\n",
        "\n",
        "If you want the output in a text file simply uncomment the three \"outF\" lines in the code.  \n",
        "\n",
        "**Note**: There are two issues using wget commands in Google Colab. If the command does not change the image name and only has the folder, then it may fail to import.  To fix this I have a \"counter\" variable which counts up from 1.  This is initialized before retriving the image data.  Take a look at the returned wget commands to see how they are formatted and feel free to change it if you like.\n",
        "\n",
        "The other issue is getting Google Colab to download data with a Python script, it seems to corrupt files downloaded in this way.  The best workaround is to save wget commands and then copy and run them in a code box.\n",
        "\n",
        "wget commands in Google Colab need a \"!\" in front like so:\n",
        "\n",
        "`!wget http://images.cocodataset.org/val2017/000000439715.jpg`\n",
        "\n",
        "The code below puts this in for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5r9Rr6tmBoT"
      },
      "source": [
        "counter = 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnl02UeRdZSx"
      },
      "source": [
        "# This code is created by Matthew Graham\n",
        "from ztfquery import query, buildurl\n",
        "\n",
        "#outF = open(\"nebulousData.txt\", \"a\")    # creates a file if it does not exist to print into\n",
        "\n",
        "ra, dec, size = 86.5546, -0.1014, 10\n",
        "zquery = query.ZTFQuery()\n",
        "zquery.load_metadata(kind = \"sci\", radec=[ra, dec]) #, size = 0.01)\n",
        "mt = zquery.metatable\n",
        "print(len(mt))\n",
        "for i, m in mt.iterrows():\n",
        "    filename = f\"ztf_{m['filefracday']}_{m['field']:0>6}_{m['filtercode']}_c{m['ccdid']:0>2}_o_q{m['qid']}_sciimg.fits\"\n",
        "    furl = buildurl.filename_to_scienceurl(filename)\n",
        "    url = f\"{furl}?center={ra},{dec}&size={size}arcsec&gzip=false\"\n",
        "    cmd = f'''!wget --auth-no-challenge --user=USERID --password=PASSWORD \"{url}\" -q -O custom_data/train/label1/img{counter}.jpg'''\n",
        "    counter += 1\n",
        "    #outF.write(cmd)\n",
        "    #outF.write(\"\\n\")\n",
        "    #print(cmd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Piot9wM9GdG7"
      },
      "source": [
        "Now verify that the data is successfully downloaded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzzoAbQ4GgdD"
      },
      "source": [
        "!ls custom_data/val/label1/\n",
        "!ls custom_data/train/label1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU1LGx61ma0L"
      },
      "source": [
        "## Splitting Up the Image Data\n",
        "\n",
        "Because this document uses a Supervised Resnet-50 model for training, the data must be split into training images and testing images.  These will be placed in their respective folders /train and /val (evalutation). \n",
        "\n",
        "It appears like this:\n",
        "- /custom_data/train/label1 \n",
        "- /custom_data/val/label1  \n",
        "\n",
        "The following code takes a .txt file and randomly splits it into two files, one for training and one for testing.  By default it will take 25% of data for training and 75% for testing, feel free to make changes.\n",
        "\n",
        "You should have access to nebulous.txt and nonNebulous.txt which work properly with this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7lKijpgnczj"
      },
      "source": [
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "#seed(132)    # If you would like to seed the randomness\n",
        "\n",
        "file1 = open(\"data.txt\", \"r\")  # The file you are reading from\n",
        "lines = file1.readlines()\n",
        "outF1 = open(\"train.txt\", \"a\")   # The data sources you will use to train\n",
        "outF2 = open(\"test.txt\", \"a\")    # The data sources you will use to test\n",
        "for line in lines:\n",
        "  if (random() < .75):      # Currently set for 25% training images and 75% for testing\n",
        "    outF2.write(line)\n",
        "    outF2.write(\"\\n\")\n",
        "  else:\n",
        "    outF1.write(cmd)\n",
        "    outF1.write(\"\\n\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step is to register the custom data you created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Q6LCqaWjl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249f4a51-7fdb-4bac-d5a8-ce5489ac9a1b"
      },
      "source": [
        "json_data = {\n",
        "    \"custom_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/vissl/custom_data/train\", \"/content/vissl/custom_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/vissl/custom_data/val\", \"/content/vissl/custom_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/vissl/configs/config/dataset_catalog.json\", append_to_json=False )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, verify that the dataset is registered with VISSL. Do this with a query of VISSL's dataset catalog as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "c2c3c0af-5f2d-4c07-aa45-19d8b1b62478"
      },
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"custom_data_folder\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['custom_data_folder']\n",
            "{'train': ['/content/vissl/custom_data/train', '/content/vissl/custom_data/train'], 'val': ['/content/vissl/custom_data/val', '/content/vissl/custom_data/val']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "You are ready to train the model. VISSL supports training on a wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use other datasets.\n",
        "\n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "The training command looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v0HvauIj9S2"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=supervised_1gpu_resnet_example \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[custom_data_folder] \\\n",
        "    config.DATA.TRAIN.DATA_PATHS=[/content/vissl/custom_data/train] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[custom_data_folder] \\\n",
        "    config.DATA.TEST.DATA_PATHS=[/content/vissl/custom_data/val] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.OPTIMIZER.num_epochs=2 \\\n",
        "    config.OPTIMIZER.param_schedulers.lr.values=[0.01,0.001] \\\n",
        "    config.OPTIMIZER.param_schedulers.lr.milestones=[1] \\\n",
        "    config.TENSORBOARD_SETUP.USE_TENSORBOARD=true \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And you are done!! You now have a Supervised ResNet-50 model trained on a custom dataset and available in `checkpoints/model_final_checkpoint_phase2.torch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFUcTj00B_a"
      },
      "source": [
        "## Training logs, checkpoints, metrics\n",
        "\n",
        "VISSL dumps model checkpoints in the checkpoint directory specified by the user. In the above example, we used `./checkpoints` directory. Let's take a look at the content of the checkpoint directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GzuqJWa0XSl"
      },
      "source": [
        "ls checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjNKDNLQ0crO"
      },
      "source": [
        "We notice:\n",
        "- model checkpoints `.torch` files after every epoch, \n",
        "- model training log `log.txt` which has the full stdout but saved in file\n",
        "- `metrics.json` if your training calculated some metrics, those metrics values will be saved there.\n",
        "- `tb_logs` which are the tensorboard events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaLMe8qwe4ln"
      },
      "source": [
        "# Understanding the Training Command\n",
        "\n",
        "Let's understand the training command we used above. You override the settings in our configuration file to train the desired setting of the model. In the example, we override the dataset to use, #images/gpu, number of GPUs to use and optimizer settings like #epochs and learning rate drops.\n",
        "\n",
        "```\n",
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=supervised_1gpu_resnet_example \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.DATA_PATHS=[/content/dummy_data/train] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.DATA_PATHS=[/content/dummy_data/val] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.OPTIMIZER.num_epochs=2 \\\n",
        "    config.OPTIMIZER.param_schedulers.lr.values=[0.01,0.001] \\\n",
        "    config.OPTIMIZER.param_schedulers.lr.milestones=[1] \\\n",
        "    config.TENSORBOARD_SETUP.USE_TENSORBOARD=true \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints\"\n",
        "```\n",
        "\n",
        "We can understand each line as below:\n",
        "\n",
        "- `config=supervised_1gpu_resnet_example` -> specify the config file for supervised training\n",
        "- `config.DATA.TRAIN.DATA_SOURCES=[disk_folder] config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]` -> specify the data source for training i.e. `disk_folder`\n",
        "- `config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]` -> specify the dataset name i.e. `dummy_data_folder`. We registered this dataset above.\n",
        "- `config.DATA.TRAIN.DATA_PATHS=[/content/dummy_data/train]` -> another way of specifying where the data is on the disk. The example config file provided has some dummy paths set. We must override those with our desired paths.\n",
        "- `config.DATA.TEST.DATA_SOURCES=[disk_folder] config.DATA.TEST.LABEL_SOURCES=[disk_folder] config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]` -> similar settings for Test dataset.\n",
        "- `config.DATA.TEST.DATA_PATHS=[/content/dummy_data/val]` -> another way of specifying where the data is on the disk. The example config file provided has some dummy paths set. We must override those with our desired paths.\n",
        "- `config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 config.DATA.TEST.BATCHSIZE_PER_REPLICA=2` -> specify 2 img/gpu to use for both `TRAIN` and `TEST`.  \n",
        "\n",
        "- `config.DISTRIBUTED.NUM_NODES=1 config.DISTRIBUTED.NUM_PROC_PER_NODE=1` -> specify the #gpus=1 and #machines=1\n",
        "\n",
        "- `config.OPTIMIZER.num_epochs=2 config.OPTIMIZER.param_schedulers.lr.values=[0.01,0.001] config.OPTIMIZER.param_schedulers.lr.milestones=[1]` -> specify #epochs=2 and drop learning rate after 1 epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjoEHL5be0l6"
      },
      "source": [
        "# Understanding Training stdout\n",
        "\n",
        "The following output indicates that the training is starting on `rank=0`. Similar output will be printed for each rank.\n",
        "```\n",
        "####### overrides: ['hydra.verbose=true', 'config=supervised_1gpu_resnet_example', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.DATA_PATHS=[/content/dummy_data/train]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.DATA_PATHS=[/content/dummy_data/val]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.OPTIMIZER.num_epochs=2', 'config.OPTIMIZER.param_schedulers.lr.values=[0.01,0.001]', 'config.OPTIMIZER.param_schedulers.lr.milestones=[1]', 'config.TENSORBOARD_SETUP.USE_TENSORBOARD=true', 'config.CHECKPOINT.DIR=./checkpoints', 'hydra.verbose=true']\n",
        "INFO 2021-01-25 20:04:50,636 __init__.py:  32: Provided Config has latest version: 1\n",
        "INFO 2021-01-25 20:04:50,638 run_distributed_engines.py: 163: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:56229\n",
        "INFO 2021-01-25 20:04:50,638 train.py:  66: Env set for rank: 0, dist_rank: 0\n",
        "```\n",
        "\n",
        "VISSL is designed for reproducible research, so the training script will first print out the running configuration -- the environment variables, versions of various libraries, the full training config, data size, model etc.\n",
        "\n",
        "The training will start afterwards and we see output like:\n",
        "\n",
        "```\n",
        "INFO 2021-01-25 20:05:01,116 state_update_hooks.py:  98: Starting phase 0 [train]\n",
        "INFO 2021-01-25 20:05:04,574 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 1; lr: 0.00078; loss: 7.07915; btime(ms): 6923; eta: 0:01:02; peak_mem: 2595M\n",
        "INFO 2021-01-25 20:05:04,828 tensorboard_hook.py: 188: Logging metrics. Iteration 5\n",
        "INFO 2021-01-25 20:05:04,839 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 5; lr: 0.00078; loss: 0.81495; btime(ms): 1437; eta: 0:00:07; peak_mem: 2595M\n",
        "INFO 2021-01-25 20:05:04,839 trainer_main.py: 194: Meters synced\n",
        "INFO 2021-01-25 20:05:10,516 log_hooks.py: 346: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 30.0}, 'top_5': {0: 60.0}}\n",
        "INFO 2021-01-25 20:05:10,516 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
        "INFO 2021-01-25 20:05:10,516 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
        "INFO 2021-01-25 20:05:10,517 log_hooks.py: 283: [phase: 0] Saving checkpoint to ./checkpoints\n",
        "INFO 2021-01-25 20:05:10,839 log_hooks.py: 312: Saved checkpoint: ./checkpoints/model_phase0.torch\n",
        "INFO 2021-01-25 20:05:10,839 log_hooks.py: 316: Creating symlink...\n",
        "INFO 2021-01-25 20:05:10,839 log_hooks.py: 320: Created symlink: ./checkpoints/checkpoint.torch\n",
        "```\n",
        "\n",
        "You can see the training stats printed out like LR, batch time, etc. VISSL also prints out the GPU memory usage and the ETA (approximate time for the experiment to finish)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW5k5mRCe94f"
      },
      "source": [
        "# Understanding YAML Config File\n",
        "\n",
        "We can now try to understand the train config file.\n",
        "\n",
        "\n",
        "## Data\n",
        "\n",
        "The input data and labels needed to train the model are specified under the `DATA` key. The training and testing data are specified under `DATA.TRAIN` and `DATA.TEST`. For example,\n",
        "\n",
        "```yaml\n",
        "DATA:\n",
        "  TRAIN:\n",
        "    DATA_SOURCES: [disk_folder]\n",
        "    DATA_PATHS: [\"<path to train folder>\"]\n",
        "    LABEL_SOURCES: [disk_folder]\n",
        "    DATASET_NAMES: [imagenet1k_folder]\n",
        "    BATCHSIZE_PER_REPLICA: 32\n",
        "```\n",
        "This specifies that the model will train on the images provided in the folder `DATA.TRAIN.DATA_PATHS` and infer the labels from the directory structure of the images. The model is trained with a batchsize of 32 images/GPU. VISSL provides a `configs/config/dataset_catalog.json` to easily specify dataset paths in one place rather than repeat them in each config file. In our example above, we saw how to use the `dataset_catalog.json`.\n",
        "\n",
        "\n",
        "## Data Transforms\n",
        "The image transforms are specified in `TRANSFORMS` and generally wrap the torchvision image transforms. One can easily compose together multiple transforms by specifying them in the config file, or implement their own custom image transforms. VISSL uses such compositionality of data transforms for implementing many self-supervised methods as well.\n",
        "For example, in our training, we specify the transforms as below:\n",
        "\n",
        "```yaml\n",
        "TRANSFORMS:\n",
        "  - name: RandomResizedCrop\n",
        "    size: 224\n",
        "  - name: RandomHorizontalFlip\n",
        "  - name: ColorJitter\n",
        "    brightness: 0.4\n",
        "    contrast: 0.4\n",
        "    saturation: 0.4\n",
        "    hue: 0.4\n",
        "  - name: ToTensor\n",
        "  - name: Normalize\n",
        "    mean: [0.485, 0.456, 0.406]\n",
        "    std: [0.229, 0.224, 0.225]\n",
        "```\n",
        "\n",
        "## Model\n",
        "VISSL specifies the model as a `TRUNK` (the base ConvNet) and a `HEAD` (the classification or task-specific parameters). This allows one to cleanly separate the logic between the task itself and the ConvNet. Multiple model trunks (see listing under `vissl/model/trunks`) can be used for the same task.\n",
        "\n",
        "A ResNet-50 model that outputs classification scores for 1000 classes (the number of classes in ImageNet) is specified as\n",
        "\n",
        "```yaml\n",
        "MODEL:\n",
        "  TRUNK:\n",
        "    NAME: resnet\n",
        "    TRUNK_PARAMS:\n",
        "      RESNETS:\n",
        "        DEPTH: 50\n",
        "  HEAD:\n",
        "    PARAMS: [\n",
        "      [\"mlp\", {\"dims\": [2048, 1000]}],\n",
        "    ]\n",
        "```\n",
        "Here `TRUNK` specifies the base ConvNet architecture, and `HEAD` specifies a single fully connected layer (special case of a MLP) that produces 1000 outputs.\n",
        "\n",
        "VISSL automatically sets the model to eval mode when using the data in `DATA.TEST`. This ensures that layers such as `BatchNorm`, `Dropout` behave correctly when used to report test set accuracies.\n",
        "\n",
        "## Loss and Optimizer\n",
        "The loss and optimizer are specified under the `LOSS` and `OPTIMIZER` keys. VISSL losses behave similar to the default `torch.nn` losses.\n",
        "\n",
        "Example: we used cross entropy loss \n",
        "```yaml\n",
        "LOSS:\n",
        "  name: cross_entropy_multiple_output_single_target\n",
        "  cross_entropy_multiple_output_single_target:\n",
        "    ignore_index: -1\n",
        "```\n",
        "\n",
        "Example, we used the optimizer (after overriding with command line params:\n",
        "The `OPTIMIZER` contains information about the base optimizer (SGD in this case) and the learning rate scheduler (`OPTIMIZER.param_schedulers`).\n",
        "\n",
        "```yaml\n",
        "OPTIMIZER:\n",
        "  name: sgd\n",
        "  weight_decay: 0.0001\n",
        "  momentum: 0.9\n",
        "  num_epochs: 105\n",
        "  nesterov: True\n",
        "  regularize_bn: False\n",
        "  regularize_bias: True\n",
        "  param_schedulers:\n",
        "    lr:\n",
        "      # learning rate is automatically scaled based on batch size\n",
        "      auto_lr_scaling: \n",
        "        auto_scale: true\n",
        "        base_value: 0.1\n",
        "        base_lr_batch_size: 256 # learning rate of 0.1 is used for batch size of 256\n",
        "      name: multistep\n",
        "      # We want the learning rate to drop by 1/10 at epochs [1]\n",
        "      milestones: [1] # epochs at which to drop the learning rate (N vals)\n",
        "      values: [0.01,0.001] # the exact values of learning rate (N+1 vals)\n",
        "      update_interval: epoch\n",
        "```\n",
        "\n",
        "## Measuring Accuracy\n",
        "Accuracy meters are specified under `METERS` and measure the top-1 and top-5 accuracies.\n",
        "\n",
        "Example:\n",
        "```yaml\n",
        "METERS:\n",
        "  name: accuracy_list_meter\n",
        "  accuracy_list_meter:\n",
        "    num_meters: 1\n",
        "    topk_values: [1, 5]\n",
        "```\n",
        "\n",
        "## Number of gpus\n",
        "The number of GPUs and number of nodes are specified under `DISTRIBUTED`. VISSL seamlessly runs the same code on either a single GPU or across multiple nodes/GPUs.\n",
        "\n",
        "Example:\n",
        "```\n",
        "DISTRIBUTED:\n",
        "  BACKEND: nccl\n",
        "  NUM_NODES: 1\n",
        "  NUM_PROC_PER_NODE: 1 # 1 GPU\n",
        "  RUN_ID: auto\n",
        "```\n",
        "\n",
        "If running on more than one node, you will need to run this command on each of the nodes. \n",
        "\n",
        "\n",
        "**NOTE**: The batch size specified in the configs under `DATA.TRAIN.BATCHSIZE_PER_REPLICA` (denoted as `B`) is per GPU. So if you run your code on `N` nodes with `G` gpus each, then the total effective batch size is `B*N*G`.\n",
        "Since running on multiple GPUs changes the effective batch size, you may also want to use learning rate warmup (see the [ImageNet in 1 hour paper](https://arxiv.org/abs/1706.02677)).\n",
        "Scaling the learning rate according to the batch size is important for distributed training. VISSL can automatically do this for you.\n",
        "\n",
        "### Auto-scaling the LR\n",
        "\n",
        "To make distributed training even simpler, VISSL can automatically scale the learning rate depending on the total batch size used. This is controlled by the flag `OPTIMIZER.param_schedulers.lr.auto_lr_scaling` which can be set to True to enable auto-scaling. By default the learning rate is scaled linearly with the batch size (see the [ImageNet in 1 hour paper](https://arxiv.org/abs/1706.02677)).\n",
        "\n",
        "We specify a `base_lr_batch_size` when creating the learning rate scheduler. At run time, the learning rate, VISSL automatically computes the run_time_batch_size and the learning rate used is multiplied by (`run_time_batch_size / base_lr_batch_size`). The autoscaling magic resides in `vissl/utils/hydra_config.py`.\n",
        "\n",
        "```yaml\n",
        "OPTIMIZER:\n",
        "  param_schedulers:\n",
        "    lr:\n",
        "      auto_lr_scaling: # learning rate is automatically scaled based on batch size\n",
        "        auto_scale: true\n",
        "        base_value: 0.1\n",
        "        base_lr_batch_size: 256 # learning rate of 0.1 is used for batch size of 256\n",
        "```\n",
        "\n",
        "## Mixed Precision or FP16 training\n",
        "If you installed Apex above, you can easily train the model using mixed precision. This requires adding the following lines to the config file under the MODEL\n",
        "\n",
        "```yaml\n",
        "AMP_PARAMS:\n",
        "  USE_AMP: True\n",
        "  AMP_ARGS: {\"opt_level\": \"O1\"}\n",
        "```\n",
        "This will run the model using the `O1` setting in apex which should generally result in stable training while saving GPU memory (and possibly faster training depending on the GPU architecture). See the [apex documentation for more information on what the different mixed precision flags](https://nvidia.github.io/apex/amp.html#opt-levels).\n",
        "\n",
        "## Using SyncBatchNorm in the model\n",
        "This can be specified in the config under the `MODEL`\n",
        "\n",
        "```yaml\n",
        "SYNC_BN_CONFIG:\n",
        "  CONVERT_BN_TO_SYNC_BN: True\n",
        "  SYNC_BN_TYPE: pytorch\n",
        "```\n",
        "If you have apex installed, you can use a faster version of `SyncBatchNorm` by\n",
        "\n",
        "```yaml\n",
        "SYNC_BN_CONFIG:\n",
        "  CONVERT_BN_TO_SYNC_BN: True\n",
        "  SYNC_BN_TYPE: apex\n",
        "  GROUP_SIZE: 8 # set to number of GPUs per node for fast performance.\n",
        "```\n",
        "Our model definitions are written such that one can easily replace `BatchNorm` with other normalization functions (`LayerNorm, GroupNorm` etc.) by changing arguments in the config file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIYLR6cki8Sr"
      },
      "source": [
        "less configs/config/supervised_1gpu_resnet_example.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni3TizhIvWmK"
      },
      "source": [
        "# Visualizing Tensorboard Logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8A7KUFavcCZ"
      },
      "source": [
        "If you have enabled `config.TENSORBOARD_SETUP.USE_TENSORBOARD=true` , you will see the tensorboard events dumped in `tb_logs/` directory. You can use this to visualize the events in tensorboard as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOCAtXFor9Sd"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "!kill 490\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir checkpoints/tb_logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}